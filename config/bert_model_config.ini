[ZHWIKI_PRETRAIN]
word2idx_path = /data/work/dl_project/data/bert_pre_trained_model/zhwiki_bert/bert_word2idx_extend.json
state_dict_dir = /data/work/dl_project/data/bert_pre_trained_model/zhwiki_bert
vocab_size = 32162
num_workers = 0
train_corpus_path = /corpus/zhwiki/bert_train_wiki.txt
test_corpus_path = /corpus/zhwiki/bert_test_wiki.txt
[SENTIMENT]
word2idx_path = /data/work/dl_project/data/bert_pre_trained_model/hotel_reviews_sentiment_bert/bert_word2idx_extend.json
state_dict_dir = /data/work/dl_project/data/bert_pre_trained_model/hotel_reviews_sentiment_bert
vocab_size = 32162
num_workers = 0
train_corpus_path = /corpus/hotel_reviews/train_sentiment.txt
test_corpus_path = /corpus/hotel_reviews/test_sentiment.txt
[THUC_NEWS]
data_dir = /data/work/dl_project/data/corpus/thuc_news
vocab_file = /data/work/dl_project/data/bert_pre_trained_model/chinese_wwm_ext_tensorflow/vocab.txt
bert_config_file = /data/work/dl_project/data/bert_pre_trained_model/chinese_wwm_ext_tensorflow/bert_config.json
output_dir = /data/work/dl_project/data/model/thuc_news
init_checkpoint = /data/work/dl_project/data/bert_pre_trained_model/chinese_wwm_ext_tensorflow/bert_model.ckpt
do_lower_case = True
max_seq_length = 512
train_batch_size = 64
eval_batch_size = 8
predict_batch_size = 8
learning_rate = 5e-5
num_train_epochs = 3.0
warmup_proportion = 0.1
save_checkpoints_steps = 1000
iterations_per_loop = 1000
use_tpu = False
tpu_name = None
tpu_zone = None
gcp_project = None
num_tpu_cores = 8
master = None