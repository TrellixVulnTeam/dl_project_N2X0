[THUC_NEWS]
data_dir = /data/work/dl_project/data/corpus/thuc_news
vocab_file = /data/work/dl_project/data/bert_pre_trained_model/chinese_wwm_ext_tensorflow/vocab.txt
bert_config_file = /data/work/dl_project/data/bert_pre_trained_model/chinese_wwm_ext_tensorflow/bert_config.json
output_dir = /data/work/dl_project/data/model/thuc_news/bert_output
init_checkpoint = /data/work/dl_project/data/bert_pre_trained_model/chinese_wwm_ext_tensorflow/bert_model.ckpt
label2idx_path = /data/work/dl_project/data/corpus/thuc_news/label2idx.json
sequence_length = 128
train_batch_size = 32
eval_batch_size = 32
predict_batch_size = 8
learning_rate = 5e-5
num_train_epochs = 3
warmup_proportion = 0.1
checkpoint_every = 1000
save_checkpoints_steps = 1000
iterations_per_loop = 1000
model_name = bert_classifier
num_classes = 14