[DEAFULT]
# 模型名称
model_name = textcnn
# 数据目录(语料文件\映射文件)
data_path =
# 输出目录(模型文件\日志文件\临时文件等)
output_path =
# 模型目录
ckpt_model_path =
# 词表映射文件
word2idx_file =
# label映射文件
label2idx_file =
# 预训练embedding文件
pretrain_embedding_file =
# 停用词文件
stopwords_file =
# 类别数,二分类时置为1,多分类时置为实际类别数
num_labels =
# 字\词向量维度
embedding_dim = 300
# 字典(词表)大小
vocab_size = 20000
# 序列长度,每句话处理成的长度(短填长切)
sequence_length = 512
# 学习速率
learning_rate = 0.001
# 学习率衰减系数
learning_decay_rate = 0.99
# 迭代多少轮就衰减的度量值,可叫作衰减速度
learning_decay_steps = 10000
# 是否训练
is_training = True
# 卷积核尺寸, a list of int. e.g. [3,4,5]
filter_sizes = [3,4,5]
# 卷积核数量(channels数)
num_filters = 64
# 保留神经元的比例,随机失活
dropout_keep_prob = 1.0
# 优化器
optimization = adam
# L2正则化的系数，主要对全连接层的参数正则化
l2_reg_lambda = 0.0
# 梯度的最大范数
max_grad_norm = 5.0
# 全样本迭代次数
num_epochs = 1
# 批样本(mini-batch)大小
batch_size = 64
# 迭代多少step验证一次模型
eval_every_step = 100
# 迭代多少step保存一次模型
save_checkpoints_steps = 100
# 若超过100个batch(epoch)验证集指标还没提升，则提前结束训练
require_improvement = 100



[THUC_NEWS]
data_path = /data/work/dl_project/data/corpus/thuc_news
output_path = /data/work/dl_project/data/model/thuc_news/word_textcnn_output
label2idx_file = /data/work/dl_project/data/corpus/thuc_news/label2idx.json
# pretrain_embedding_file = /data/work/dl_project/data/pretrained_embedding/sgns.sogou.char
sequence_length = 512
num_labels = 14
embedding_dim = 300
vocab_size = 10000
num_filters = 64
filter_sizes = [3,4,5]
dropout_keep_prob = 0.8
optimization = adam
learning_rate = 0.0001
l2_reg_lambda = 0.0
max_grad_norm = 5.0
num_epochs = 10
batch_size = 128
eval_every_step = 500
require_improvement = 100
model_name = textcnn